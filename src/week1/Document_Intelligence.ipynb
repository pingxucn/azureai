{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import datetime\n",
    "from azure.storage.blob import (\n",
    "    BlobServiceClient,\n",
    "    ContainerClient,\n",
    "    BlobSasPermissions,\n",
    "    generate_container_sas\n",
    ")\n",
    "from azure.core.exceptions import ResourceNotFoundError\n",
    "from azure.ai.formrecognizer import FormRecognizerClient\n",
    "from azure.ai.formrecognizer import FormTrainingClient\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "\n",
    "\n",
    "def create_service_sas_container(container_client: ContainerClient, account_key: str):\n",
    "    # Create a SAS token that's valid for one day, as an example\n",
    "    start_time = datetime.datetime.now(datetime.timezone.utc)\n",
    "    expiry_time = start_time + datetime.timedelta(days=1)\n",
    "\n",
    "    sas_token = generate_container_sas(\n",
    "        account_name=container_client.account_name,\n",
    "        container_name=container_client.container_name,\n",
    "        account_key=account_key,\n",
    "        permission=BlobSasPermissions(read=True, list=True),\n",
    "        expiry=expiry_time,\n",
    "        start=start_time\n",
    "    )\n",
    "    return sas_token\n",
    "\n",
    "\n",
    "def use_service_sas_container(blob_service_client: BlobServiceClient):\n",
    "    container_client = blob_service_client.get_container_client(container=\"speechtraining\")\n",
    "    # Assumes the service client object was created with a shared access key\n",
    "    sas_token = create_service_sas_container(container_client=container_client, account_key=blob_service_client.credential.account_key)\n",
    "\n",
    "    # <Snippet_use_service_sas_container>\n",
    "    # The SAS token string can be appended to the resource URL with a ? delimiter\n",
    "    # or passed as the credential argument to the client constructor\n",
    "    sas_url = f\"{container_client.url}?{sas_token}\"\n",
    "    # Create a ContainerClient object with SAS authorization\n",
    "    container_client_sas = ContainerClient.from_container_url(container_url=sas_url)\n",
    "    return sas_url\n",
    "\n",
    "\n",
    "def main(): \n",
    "    try: \n",
    "        # Get configuration settings \n",
    "        # load_dotenv()\n",
    "        storage_account_name=\"rstorage2speech\"\n",
    "        storage_account_key=os.getenv('AZURE_STORAGE_KEY')\n",
    "\n",
    "        form_endpoint = os.getenv('AZURE_FORM_RECOGNIZER_ENDPOINT')\n",
    "        form_key = os.getenv('AZURE_FORM_RECOGNIZER_KEY')\n",
    "\n",
    "        account_url = f\"https://{storage_account_name}.blob.core.windows.net\"\n",
    "        blob_service_client_account_key = BlobServiceClient(account_url, credential=storage_account_key)\n",
    "\n",
    "        trainingDataUrl = use_service_sas_container(blob_service_client=blob_service_client_account_key)\n",
    "        print(f\"trainingDataUrl : {trainingDataUrl}\")\n",
    "\n",
    "        # Authenticate Form Training Client\n",
    "        # form_recognizer_client = FormRecognizerClient(form_endpoint, AzureKeyCredential(form_key))\n",
    "        form_training_client = FormTrainingClient(form_endpoint, AzureKeyCredential(form_key))\n",
    "\n",
    "        # Train model \n",
    "        poller = form_training_client.begin_training(trainingDataUrl, use_training_labels=True)\n",
    "        model = poller.result()\n",
    "\n",
    "        print(\"Model ID: {}\".format(model.model_id))\n",
    "        print(\"Status: {}\".format(model.status))\n",
    "        print(\"Training started on: {}\".format(model.training_started_on))\n",
    "        print(\"Training completed on: {}\".format(model.training_completed_on))\n",
    "\n",
    "    except Exception as ex:\n",
    "        print(ex)\n",
    "\n",
    "if __name__ == '__main__': \n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------Analyzing document #1--------\n",
      "Document has type PDFExtract1106beta\n",
      "Document has confidence 0.964\n",
      "Document was analyzed by model with ID PDFExtract1106beta\n",
      "......found field of type 'string' with value 'SELF-RAG: LEARNING TO RETRIEVE, GENERATE, AND CRITIQUE THROUGH SELF-REFLECTION Akari Asait, Zeqiu Wut, Yizhong Wangts, Avirup Sil+, Hannaneh Hajishirzits +University of Washington $Allen Institute for AI #IBM Research AI {akari, zeqiuwu, yizhongw, hannaneh}@cs.washington.edu, avi@us.ibm.com' and with confidence 0.151\n",
      "......found field of type 'string' with value 'Preprint.' and with confidence None\n",
      "......found field of type 'string' with value 'ABSTRACT Despite their remarkable capabilities, large language models (LLMs) often produce responses containing factual inaccuracies due to their sole reliance on the paramet- ric knowledge they encapsulate. Retrieval-Augmented Generation (RAG), an ad hoc approach that augments LMs with retrieval of relevant knowledge, decreases such issues. However, indiscriminately retrieving and incorporating a fixed number of retrieved passages, regardless of whether retrieval is necessary, or passages are relevant, diminishes LM versatility or can lead to unhelpful response generation. We introduce a new framework called Self-Reflective Retrieval-Augmented Gen- eration (SELF-RAG) that enhances an LM's quality and factuality through retrieval and self-reflection. Our framework trains a single arbitrary LM that adaptively retrieves passages on-demand, and generates and reflects on retrieved passages and its own generations using special tokens, called reflection tokens. Generating reflection tokens makes the LM controllable during the inference phase, enabling it to tailor its behavior to diverse task requirements. Experiments show that SELF- RAG (7B and 13B parameters) significantly outperforms state-of-the-art LLMs and retrieval-augmented models on a diverse set of tasks. Specifically, SELF-RAG outperforms ChatGPT and retrieval-augmented Llama2-chat on Open-domain QA, reasoning and fact verification tasks, and it shows significant gains in improving factuality and citation accuracy for long-form generations relative to these models.1' and with confidence 0.044\n",
      "Total number of pages: 30\n",
      "-----------------------------------\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "# from dotenv import load_dotenv\n",
    "\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.ai.formrecognizer import DocumentAnalysisClient\n",
    "\n",
    "def main(): \n",
    "        \n",
    "    try: \n",
    "    \n",
    "        # Get configuration settings \n",
    "        # load_dotenv()\n",
    "        form_endpoint = os.getenv('AZURE_FORM_RECOGNIZER_ENDPOINT')\n",
    "        form_key = os.getenv('AZURE_FORM_RECOGNIZER_KEY')\n",
    "        \n",
    "        # Create client using endpoint and key\n",
    "        document_analysis_client = DocumentAnalysisClient(\n",
    "            endpoint=form_endpoint, credential=AzureKeyCredential(form_key)\n",
    "        )\n",
    "\n",
    "        # Model ID from when you trained your model.\n",
    "        model_id = os.getenv('AZURE_FORM_RECOGNIZER_MODEL_ID')\n",
    "\n",
    "        # Test trained model with a new form \n",
    "        ## from azure storage\n",
    "        # file_sasurl = \"https://rstorage2speech.blob.core.windows.net/speechtest/2310.11511.pdf?sp=r&st=2023-11-08T00:25:47Z&se=2023-11-08T08:25:47Z&spr=https&sv=2022-11-02&sr=b&sig=0gIGt042dSVHPbezQZOj4D%2FD9XGS8qt5s5u3vk4DkOc%3D\"\n",
    "        # poller = document_analysis_client.begin_analyze_document_from_url(model_id=model_id, document_url=file_sasurl)\n",
    "\n",
    "        ## from local file\n",
    "        file_path = \"../../data/pdf/test/2308.00479.pdf\"\n",
    "        with open(file_path, \"rb\") as f: \n",
    "            poller = document_analysis_client.begin_analyze_document(model_id=model_id, document=f)\n",
    "\n",
    "        result = poller.result()\n",
    "        \n",
    "        for idx, document in enumerate(result.documents):\n",
    "            print(\"--------Analyzing document #{}--------\".format(idx + 1))\n",
    "            print(\"Document has type {}\".format(document.doc_type))\n",
    "            print(\"Document has confidence {}\".format(document.confidence))\n",
    "            print(\"Document was analyzed by model with ID {}\".format(result.model_id))\n",
    "            for name, field in document.fields.items():\n",
    "                field_value = field.value if field.value else field.content\n",
    "                print(\"......found field of type '{}' with value '{}' and with confidence {}\".format(field.value_type, field_value, field.confidence))\n",
    "\n",
    "\n",
    "        # iterate over tables, lines, and selection marks on each page\n",
    "        print(f\"Total number of pages: {len(result.pages)}\")\n",
    "        # for page in result.pages:\n",
    "        #     print(\"\\nLines found on page {}\".format(page.page_number))\n",
    "        #     for line in page.lines:\n",
    "        #         print(\"...Line '{}'\".format(line.content.encode('utf-8')))\n",
    "        #     for word in page.words:\n",
    "        #         print(\n",
    "        #             \"...Word '{}' has a confidence of {}\".format(\n",
    "        #                 word.content.encode('utf-8'), word.confidence\n",
    "        #             )\n",
    "        #         )\n",
    "        #     for selection_mark in page.selection_marks:\n",
    "        #         print(\n",
    "        #             \"...Selection mark is '{}' and has a confidence of {}\".format(\n",
    "        #                 selection_mark.state, selection_mark.confidence\n",
    "        #             )\n",
    "        #         )\n",
    "\n",
    "        # for i, table in enumerate(result.tables):\n",
    "        #     print(\"\\nTable {} can be found on page:\".format(i + 1))\n",
    "        #     for region in table.bounding_regions:\n",
    "        #         print(\"...{}\".format(i + 1, region.page_number))\n",
    "        #     for cell in table.cells:\n",
    "        #         print(\n",
    "        #             \"...Cell[{}][{}] has content '{}'\".format(\n",
    "        #                 cell.row_index, cell.column_index, cell.content.encode('utf-8')\n",
    "        #             )\n",
    "        #         )\n",
    "        print(\"-----------------------------------\")\n",
    "        \n",
    "    except Exception as ex:\n",
    "        print(ex)\n",
    "\n",
    "if __name__ == '__main__': \n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "azureai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

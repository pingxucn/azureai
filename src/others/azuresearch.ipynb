{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Azure Cognitive Search\n",
    "\n",
    "[Azure Cognitive Search](https://learn.microsoft.com/azure/search/search-what-is-azure-search) (formerly known as `Azure Search`) is a cloud search service that gives developers infrastructure, APIs, and tools for building a rich search experience over private, heterogeneous content in web, mobile, and enterprise applications.\n",
    "\n",
    "Vector search is currently in public preview. It's available through the Azure portal, preview REST API and beta client libraries. [More info](https://learn.microsoft.com/en-us/azure/search/vector-search-overview) Beta client libraries are subject to potential breaking changes, please be sure to use the SDK package version identified below. azure-search-documents==11.4.0b8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install Azure Cognitive Search SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting azure-search-documents==11.4.0b8\n",
      "  Using cached azure_search_documents-11.4.0b8-py3-none-any.whl.metadata (22 kB)\n",
      "Collecting azure-core<2.0.0,>=1.24.0 (from azure-search-documents==11.4.0b8)\n",
      "  Using cached azure_core-1.29.5-py3-none-any.whl.metadata (36 kB)\n",
      "Collecting azure-common~=1.1 (from azure-search-documents==11.4.0b8)\n",
      "  Using cached azure_common-1.1.28-py2.py3-none-any.whl (14 kB)\n",
      "Collecting isodate>=0.6.0 (from azure-search-documents==11.4.0b8)\n",
      "  Using cached isodate-0.6.1-py2.py3-none-any.whl (41 kB)\n",
      "Collecting requests>=2.18.4 (from azure-core<2.0.0,>=1.24.0->azure-search-documents==11.4.0b8)\n",
      "  Using cached requests-2.31.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: six>=1.11.0 in c:\\users\\ping\\miniconda3\\envs\\gptold\\lib\\site-packages (from azure-core<2.0.0,>=1.24.0->azure-search-documents==11.4.0b8) (1.16.0)\n",
      "Collecting typing-extensions>=4.6.0 (from azure-core<2.0.0,>=1.24.0->azure-search-documents==11.4.0b8)\n",
      "  Using cached typing_extensions-4.8.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests>=2.18.4->azure-core<2.0.0,>=1.24.0->azure-search-documents==11.4.0b8)\n",
      "  Downloading charset_normalizer-3.3.2-cp310-cp310-win_amd64.whl.metadata (34 kB)\n",
      "Collecting idna<4,>=2.5 (from requests>=2.18.4->azure-core<2.0.0,>=1.24.0->azure-search-documents==11.4.0b8)\n",
      "  Using cached idna-3.4-py3-none-any.whl (61 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests>=2.18.4->azure-core<2.0.0,>=1.24.0->azure-search-documents==11.4.0b8)\n",
      "  Using cached urllib3-2.1.0-py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests>=2.18.4->azure-core<2.0.0,>=1.24.0->azure-search-documents==11.4.0b8)\n",
      "  Downloading certifi-2023.11.17-py3-none-any.whl.metadata (2.2 kB)\n",
      "Using cached azure_search_documents-11.4.0b8-py3-none-any.whl (305 kB)\n",
      "Using cached azure_core-1.29.5-py3-none-any.whl (192 kB)\n",
      "Using cached requests-2.31.0-py3-none-any.whl (62 kB)\n",
      "Using cached typing_extensions-4.8.0-py3-none-any.whl (31 kB)\n",
      "Downloading certifi-2023.11.17-py3-none-any.whl (162 kB)\n",
      "   ---------------------------------------- 0.0/162.5 kB ? eta -:--:--\n",
      "   --------------- ------------------------ 61.4/162.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 162.5/162.5 kB 1.6 MB/s eta 0:00:00\n",
      "Downloading charset_normalizer-3.3.2-cp310-cp310-win_amd64.whl (100 kB)\n",
      "   ---------------------------------------- 0.0/100.3 kB ? eta -:--:--\n",
      "   ---------------- ----------------------- 41.0/100.3 kB ? eta -:--:--\n",
      "   ---------------- ----------------------- 41.0/100.3 kB ? eta -:--:--\n",
      "   -------------------------------------- 100.3/100.3 kB 819.1 kB/s eta 0:00:00\n",
      "Using cached urllib3-2.1.0-py3-none-any.whl (104 kB)\n",
      "Installing collected packages: azure-common, urllib3, typing-extensions, isodate, idna, charset-normalizer, certifi, requests, azure-core, azure-search-documents\n",
      "Successfully installed azure-common-1.1.28 azure-core-1.29.5 azure-search-documents-11.4.0b8 certifi-2023.11.17 charset-normalizer-3.3.2 idna-3.4 isodate-0.6.1 requests-2.31.0 typing-extensions-4.8.0 urllib3-2.1.0\n",
      "Collecting openai==0.28.1\n",
      "  Using cached openai-0.28.1-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: requests>=2.20 in c:\\users\\ping\\miniconda3\\envs\\gptold\\lib\\site-packages (from openai==0.28.1) (2.31.0)\n",
      "Collecting tqdm (from openai==0.28.1)\n",
      "  Using cached tqdm-4.66.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting aiohttp (from openai==0.28.1)\n",
      "  Downloading aiohttp-3.9.0-cp310-cp310-win_amd64.whl.metadata (7.6 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ping\\miniconda3\\envs\\gptold\\lib\\site-packages (from requests>=2.20->openai==0.28.1) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ping\\miniconda3\\envs\\gptold\\lib\\site-packages (from requests>=2.20->openai==0.28.1) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ping\\miniconda3\\envs\\gptold\\lib\\site-packages (from requests>=2.20->openai==0.28.1) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ping\\miniconda3\\envs\\gptold\\lib\\site-packages (from requests>=2.20->openai==0.28.1) (2023.11.17)\n",
      "Collecting attrs>=17.3.0 (from aiohttp->openai==0.28.1)\n",
      "  Using cached attrs-23.1.0-py3-none-any.whl (61 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp->openai==0.28.1)\n",
      "  Downloading multidict-6.0.4-cp310-cp310-win_amd64.whl (28 kB)\n",
      "Collecting yarl<2.0,>=1.0 (from aiohttp->openai==0.28.1)\n",
      "  Downloading yarl-1.9.3-cp310-cp310-win_amd64.whl.metadata (29 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp->openai==0.28.1)\n",
      "  Downloading frozenlist-1.4.0-cp310-cp310-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp->openai==0.28.1)\n",
      "  Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Collecting async-timeout<5.0,>=4.0 (from aiohttp->openai==0.28.1)\n",
      "  Using cached async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\ping\\miniconda3\\envs\\gptold\\lib\\site-packages (from tqdm->openai==0.28.1) (0.4.6)\n",
      "Using cached openai-0.28.1-py3-none-any.whl (76 kB)\n",
      "Downloading aiohttp-3.9.0-cp310-cp310-win_amd64.whl (364 kB)\n",
      "   ---------------------------------------- 0.0/364.2 kB ? eta -:--:--\n",
      "   ---------------------- ----------------- 204.8/364.2 kB 6.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 364.2/364.2 kB 3.8 MB/s eta 0:00:00\n",
      "Using cached tqdm-4.66.1-py3-none-any.whl (78 kB)\n",
      "Using cached async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Downloading frozenlist-1.4.0-cp310-cp310-win_amd64.whl (44 kB)\n",
      "   ---------------------------------------- 0.0/44.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 44.4/44.4 kB 2.1 MB/s eta 0:00:00\n",
      "Downloading yarl-1.9.3-cp310-cp310-win_amd64.whl (75 kB)\n",
      "   ---------------------------------------- 0.0/75.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 75.6/75.6 kB ? eta 0:00:00\n",
      "Installing collected packages: tqdm, multidict, frozenlist, attrs, async-timeout, yarl, aiosignal, aiohttp, openai\n",
      "Successfully installed aiohttp-3.9.0 aiosignal-1.3.1 async-timeout-4.0.3 attrs-23.1.0 frozenlist-1.4.0 multidict-6.0.4 openai-0.28.1 tqdm-4.66.1 yarl-1.9.3\n",
      "Collecting python-dotenv\n",
      "  Using cached python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
      "Installing collected packages: python-dotenv\n",
      "Successfully installed python-dotenv-1.0.0\n",
      "Collecting langchain==0.0.336\n",
      "  Using cached langchain-0.0.336-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting PyYAML>=5.3 (from langchain==0.0.336)\n",
      "  Downloading PyYAML-6.0.1-cp310-cp310-win_amd64.whl.metadata (2.1 kB)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain==0.0.336)\n",
      "  Downloading SQLAlchemy-2.0.23-cp310-cp310-win_amd64.whl.metadata (9.8 kB)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\ping\\miniconda3\\envs\\gptold\\lib\\site-packages (from langchain==0.0.336) (3.9.0)\n",
      "Collecting anyio<4.0 (from langchain==0.0.336)\n",
      "  Using cached anyio-3.7.1-py3-none-any.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in c:\\users\\ping\\miniconda3\\envs\\gptold\\lib\\site-packages (from langchain==0.0.336) (4.0.3)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain==0.0.336)\n",
      "  Using cached dataclasses_json-0.6.2-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain==0.0.336)\n",
      "  Using cached jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting langsmith<0.1.0,>=0.0.63 (from langchain==0.0.336)\n",
      "  Downloading langsmith-0.0.66-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting numpy<2,>=1 (from langchain==0.0.336)\n",
      "  Downloading numpy-1.26.2-cp310-cp310-win_amd64.whl.metadata (61 kB)\n",
      "     ---------------------------------------- 0.0/61.2 kB ? eta -:--:--\n",
      "     ------ --------------------------------- 10.2/61.2 kB ? eta -:--:--\n",
      "     ------ --------------------------------- 10.2/61.2 kB ? eta -:--:--\n",
      "     ------ --------------------------------- 10.2/61.2 kB ? eta -:--:--\n",
      "     ------ --------------------------------- 10.2/61.2 kB ? eta -:--:--\n",
      "     -------------------------------------- 61.2/61.2 kB 271.1 kB/s eta 0:00:00\n",
      "Collecting pydantic<3,>=1 (from langchain==0.0.336)\n",
      "  Using cached pydantic-2.5.1-py3-none-any.whl.metadata (64 kB)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\ping\\miniconda3\\envs\\gptold\\lib\\site-packages (from langchain==0.0.336) (2.31.0)\n",
      "Collecting tenacity<9.0.0,>=8.1.0 (from langchain==0.0.336)\n",
      "  Using cached tenacity-8.2.3-py3-none-any.whl.metadata (1.0 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\ping\\miniconda3\\envs\\gptold\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.336) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\ping\\miniconda3\\envs\\gptold\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.336) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\ping\\miniconda3\\envs\\gptold\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.336) (1.9.3)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\ping\\miniconda3\\envs\\gptold\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.336) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\ping\\miniconda3\\envs\\gptold\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.336) (1.3.1)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\ping\\miniconda3\\envs\\gptold\\lib\\site-packages (from anyio<4.0->langchain==0.0.336) (3.4)\n",
      "Collecting sniffio>=1.1 (from anyio<4.0->langchain==0.0.336)\n",
      "  Using cached sniffio-1.3.0-py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: exceptiongroup in c:\\users\\ping\\miniconda3\\envs\\gptold\\lib\\site-packages (from anyio<4.0->langchain==0.0.336) (1.2.0)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain==0.0.336)\n",
      "  Using cached marshmallow-3.20.1-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain==0.0.336)\n",
      "  Using cached typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain==0.0.336)\n",
      "  Using cached jsonpointer-2.4-py2.py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting annotated-types>=0.4.0 (from pydantic<3,>=1->langchain==0.0.336)\n",
      "  Using cached annotated_types-0.6.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting pydantic-core==2.14.3 (from pydantic<3,>=1->langchain==0.0.336)\n",
      "  Downloading pydantic_core-2.14.3-cp310-none-win_amd64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\ping\\miniconda3\\envs\\gptold\\lib\\site-packages (from pydantic<3,>=1->langchain==0.0.336) (4.8.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ping\\miniconda3\\envs\\gptold\\lib\\site-packages (from requests<3,>=2->langchain==0.0.336) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ping\\miniconda3\\envs\\gptold\\lib\\site-packages (from requests<3,>=2->langchain==0.0.336) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ping\\miniconda3\\envs\\gptold\\lib\\site-packages (from requests<3,>=2->langchain==0.0.336) (2023.11.17)\n",
      "Collecting greenlet!=0.4.17 (from SQLAlchemy<3,>=1.4->langchain==0.0.336)\n",
      "  Downloading greenlet-3.0.1-cp310-cp310-win_amd64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: packaging>=17.0 in c:\\users\\ping\\miniconda3\\envs\\gptold\\lib\\site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.7,>=0.5.7->langchain==0.0.336) (23.2)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain==0.0.336)\n",
      "  Using cached mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Using cached langchain-0.0.336-py3-none-any.whl (2.0 MB)\n",
      "Using cached anyio-3.7.1-py3-none-any.whl (80 kB)\n",
      "Using cached dataclasses_json-0.6.2-py3-none-any.whl (28 kB)\n",
      "Using cached jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading langsmith-0.0.66-py3-none-any.whl (46 kB)\n",
      "   ---------------------------------------- 0.0/46.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 46.8/46.8 kB 1.1 MB/s eta 0:00:00\n",
      "Downloading numpy-1.26.2-cp310-cp310-win_amd64.whl (15.8 MB)\n",
      "   ---------------------------------------- 0.0/15.8 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.1/15.8 MB 5.1 MB/s eta 0:00:04\n",
      "   ---------------------------------------- 0.1/15.8 MB 5.1 MB/s eta 0:00:04\n",
      "   ---------------------------------------- 0.2/15.8 MB 1.1 MB/s eta 0:00:14\n",
      "    --------------------------------------- 0.2/15.8 MB 1.3 MB/s eta 0:00:13\n",
      "    --------------------------------------- 0.3/15.8 MB 1.4 MB/s eta 0:00:12\n",
      "   - -------------------------------------- 0.6/15.8 MB 2.3 MB/s eta 0:00:07\n",
      "   -- ------------------------------------- 1.1/15.8 MB 3.4 MB/s eta 0:00:05\n",
      "   --- ------------------------------------ 1.4/15.8 MB 4.1 MB/s eta 0:00:04\n",
      "   ---- ----------------------------------- 1.8/15.8 MB 4.4 MB/s eta 0:00:04\n",
      "   ----- ---------------------------------- 2.1/15.8 MB 4.5 MB/s eta 0:00:04\n",
      "   ----- ---------------------------------- 2.2/15.8 MB 4.4 MB/s eta 0:00:04\n",
      "   ------- -------------------------------- 3.1/15.8 MB 5.8 MB/s eta 0:00:03\n",
      "   -------- ------------------------------- 3.2/15.8 MB 5.7 MB/s eta 0:00:03\n",
      "   -------- ------------------------------- 3.2/15.8 MB 5.7 MB/s eta 0:00:03\n",
      "   -------- ------------------------------- 3.2/15.8 MB 5.7 MB/s eta 0:00:03\n",
      "   -------- ------------------------------- 3.2/15.8 MB 5.7 MB/s eta 0:00:03\n",
      "   -------- ------------------------------- 3.2/15.8 MB 5.7 MB/s eta 0:00:03\n",
      "   --------- ------------------------------ 3.9/15.8 MB 4.7 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 5.0/15.8 MB 5.7 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 5.1/15.8 MB 5.6 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 5.6/15.8 MB 5.8 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 5.9/15.8 MB 5.8 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 6.4/15.8 MB 6.1 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 6.7/15.8 MB 6.1 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 6.7/15.8 MB 6.1 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 6.8/15.8 MB 5.7 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 7.2/15.8 MB 5.9 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 7.2/15.8 MB 5.9 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 7.5/15.8 MB 5.6 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 7.7/15.8 MB 5.5 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 7.8/15.8 MB 5.6 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 7.8/15.8 MB 5.3 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 7.8/15.8 MB 5.3 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 7.8/15.8 MB 5.3 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 7.8/15.8 MB 5.3 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 7.8/15.8 MB 5.3 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 7.8/15.8 MB 5.3 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 7.8/15.8 MB 5.3 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 9.0/15.8 MB 5.0 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 9.2/15.8 MB 4.9 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 9.6/15.8 MB 5.0 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 9.6/15.8 MB 5.0 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 9.6/15.8 MB 5.0 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 9.6/15.8 MB 5.0 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 9.6/15.8 MB 4.6 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 9.7/15.8 MB 4.6 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 9.7/15.8 MB 4.6 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 9.7/15.8 MB 4.6 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 9.7/15.8 MB 4.6 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 9.7/15.8 MB 4.6 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 9.7/15.8 MB 4.6 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 9.7/15.8 MB 4.6 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 9.7/15.8 MB 4.6 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 9.7/15.8 MB 4.6 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 9.9/15.8 MB 3.9 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 10.2/15.8 MB 4.0 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 10.5/15.8 MB 4.2 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 10.7/15.8 MB 4.2 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 11.2/15.8 MB 4.2 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 11.2/15.8 MB 4.2 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 11.2/15.8 MB 4.2 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 11.2/15.8 MB 4.2 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 11.2/15.8 MB 4.2 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 11.2/15.8 MB 4.2 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 11.2/15.8 MB 4.2 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 11.2/15.8 MB 4.2 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 12.0/15.8 MB 3.8 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 12.0/15.8 MB 3.7 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 12.0/15.8 MB 3.7 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 12.0/15.8 MB 3.6 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 12.0/15.8 MB 3.6 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 12.5/15.8 MB 3.6 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 12.7/15.8 MB 3.6 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 12.9/15.8 MB 3.5 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 13.1/15.8 MB 3.5 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 13.5/15.8 MB 3.8 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 13.6/15.8 MB 3.7 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 13.9/15.8 MB 3.7 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 14.1/15.8 MB 3.6 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 14.4/15.8 MB 3.6 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 14.6/15.8 MB 3.5 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 14.8/15.8 MB 3.4 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 15.0/15.8 MB 3.4 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 15.2/15.8 MB 3.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  15.5/15.8 MB 3.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  15.7/15.8 MB 3.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 15.8/15.8 MB 3.3 MB/s eta 0:00:00\n",
      "Using cached pydantic-2.5.1-py3-none-any.whl (381 kB)\n",
      "Downloading pydantic_core-2.14.3-cp310-none-win_amd64.whl (1.9 MB)\n",
      "   ---------------------------------------- 0.0/1.9 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 0.2/1.9 MB 9.0 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 0.5/1.9 MB 6.3 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 0.7/1.9 MB 5.0 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 1.0/1.9 MB 5.0 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 1.2/1.9 MB 5.4 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 1.5/1.9 MB 5.3 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 1.7/1.9 MB 5.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.9/1.9 MB 5.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.9/1.9 MB 5.0 MB/s eta 0:00:00\n",
      "Downloading PyYAML-6.0.1-cp310-cp310-win_amd64.whl (145 kB)\n",
      "   ---------------------------------------- 0.0/145.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 145.3/145.3 kB 2.9 MB/s eta 0:00:00\n",
      "Downloading SQLAlchemy-2.0.23-cp310-cp310-win_amd64.whl (2.1 MB)\n",
      "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.2/2.1 MB 6.9 MB/s eta 0:00:01\n",
      "   -------- ------------------------------- 0.4/2.1 MB 4.6 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 0.6/2.1 MB 5.3 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 0.9/2.1 MB 4.9 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 1.0/2.1 MB 4.5 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 1.1/2.1 MB 4.1 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 1.1/2.1 MB 3.8 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 1.4/2.1 MB 3.7 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 1.5/2.1 MB 3.6 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 1.6/2.1 MB 3.4 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 1.7/2.1 MB 3.5 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 1.9/2.1 MB 3.4 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 2.0/2.1 MB 3.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.1/2.1 MB 3.4 MB/s eta 0:00:00\n",
      "Using cached tenacity-8.2.3-py3-none-any.whl (24 kB)\n",
      "Using cached annotated_types-0.6.0-py3-none-any.whl (12 kB)\n",
      "Downloading greenlet-3.0.1-cp310-cp310-win_amd64.whl (287 kB)\n",
      "   ---------------------------------------- 0.0/287.9 kB ? eta -:--:--\n",
      "   ----------- ---------------------------- 81.9/287.9 kB ? eta -:--:--\n",
      "   ---------------------------------- ----- 245.8/287.9 kB 3.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 287.9/287.9 kB 3.0 MB/s eta 0:00:00\n",
      "Using cached jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
      "Using cached marshmallow-3.20.1-py3-none-any.whl (49 kB)\n",
      "Using cached typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Installing collected packages: tenacity, sniffio, PyYAML, pydantic-core, numpy, mypy-extensions, marshmallow, jsonpointer, greenlet, annotated-types, typing-inspect, SQLAlchemy, pydantic, jsonpatch, anyio, langsmith, dataclasses-json, langchain\n",
      "Successfully installed PyYAML-6.0.1 SQLAlchemy-2.0.23 annotated-types-0.6.0 anyio-3.7.1 dataclasses-json-0.6.2 greenlet-3.0.1 jsonpatch-1.33 jsonpointer-2.4 langchain-0.0.336 langsmith-0.0.66 marshmallow-3.20.1 mypy-extensions-1.0.0 numpy-1.26.2 pydantic-2.5.1 pydantic-core-2.14.3 sniffio-1.3.0 tenacity-8.2.3 typing-inspect-0.9.0\n",
      "Collecting tiktoken\n",
      "  Downloading tiktoken-0.5.1-cp310-cp310-win_amd64.whl.metadata (6.8 kB)\n",
      "Collecting regex>=2022.1.18 (from tiktoken)\n",
      "  Downloading regex-2023.10.3-cp310-cp310-win_amd64.whl.metadata (41 kB)\n",
      "     ---------------------------------------- 0.0/42.0 kB ? eta -:--:--\n",
      "     ---------------------------------------- 42.0/42.0 kB 2.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\ping\\miniconda3\\envs\\gptold\\lib\\site-packages (from tiktoken) (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ping\\miniconda3\\envs\\gptold\\lib\\site-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ping\\miniconda3\\envs\\gptold\\lib\\site-packages (from requests>=2.26.0->tiktoken) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ping\\miniconda3\\envs\\gptold\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ping\\miniconda3\\envs\\gptold\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2023.11.17)\n",
      "Downloading tiktoken-0.5.1-cp310-cp310-win_amd64.whl (759 kB)\n",
      "   ---------------------------------------- 0.0/759.8 kB ? eta -:--:--\n",
      "   -------- ------------------------------- 153.6/759.8 kB 3.1 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 512.0/759.8 kB 6.4 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 737.3/759.8 kB 5.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 759.8/759.8 kB 4.8 MB/s eta 0:00:00\n",
      "Downloading regex-2023.10.3-cp310-cp310-win_amd64.whl (269 kB)\n",
      "   ---------------------------------------- 0.0/269.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/269.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 269.6/269.6 kB ? eta 0:00:00\n",
      "Installing collected packages: regex, tiktoken\n",
      "Successfully installed regex-2023.10.3 tiktoken-0.5.1\n",
      "Collecting azure-identity==1.12\n",
      "  Using cached azure_identity-1.12.0-py3-none-any.whl (135 kB)\n",
      "Requirement already satisfied: azure-core<2.0.0,>=1.11.0 in c:\\users\\ping\\miniconda3\\envs\\gptold\\lib\\site-packages (from azure-identity==1.12) (1.29.5)\n",
      "Collecting cryptography>=2.5 (from azure-identity==1.12)\n",
      "  Using cached cryptography-41.0.5-cp37-abi3-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting msal<2.0.0,>=1.12.0 (from azure-identity==1.12)\n",
      "  Using cached msal-1.25.0-py2.py3-none-any.whl.metadata (11 kB)\n",
      "Collecting msal-extensions<2.0.0,>=0.3.0 (from azure-identity==1.12)\n",
      "  Using cached msal_extensions-1.0.0-py2.py3-none-any.whl (19 kB)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\ping\\miniconda3\\envs\\gptold\\lib\\site-packages (from azure-identity==1.12) (1.16.0)\n",
      "Requirement already satisfied: requests>=2.18.4 in c:\\users\\ping\\miniconda3\\envs\\gptold\\lib\\site-packages (from azure-core<2.0.0,>=1.11.0->azure-identity==1.12) (2.31.0)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in c:\\users\\ping\\miniconda3\\envs\\gptold\\lib\\site-packages (from azure-core<2.0.0,>=1.11.0->azure-identity==1.12) (4.8.0)\n",
      "Collecting cffi>=1.12 (from cryptography>=2.5->azure-identity==1.12)\n",
      "  Downloading cffi-1.16.0-cp310-cp310-win_amd64.whl.metadata (1.5 kB)\n",
      "Collecting PyJWT<3,>=1.0.0 (from PyJWT[crypto]<3,>=1.0.0->msal<2.0.0,>=1.12.0->azure-identity==1.12)\n",
      "  Using cached PyJWT-2.8.0-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting portalocker<3,>=1.6 (from msal-extensions<2.0.0,>=0.3.0->azure-identity==1.12)\n",
      "  Using cached portalocker-2.8.2-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting pycparser (from cffi>=1.12->cryptography>=2.5->azure-identity==1.12)\n",
      "  Using cached pycparser-2.21-py2.py3-none-any.whl (118 kB)\n",
      "Requirement already satisfied: pywin32>=226 in c:\\users\\ping\\miniconda3\\envs\\gptold\\lib\\site-packages (from portalocker<3,>=1.6->msal-extensions<2.0.0,>=0.3.0->azure-identity==1.12) (306)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ping\\miniconda3\\envs\\gptold\\lib\\site-packages (from requests>=2.18.4->azure-core<2.0.0,>=1.11.0->azure-identity==1.12) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ping\\miniconda3\\envs\\gptold\\lib\\site-packages (from requests>=2.18.4->azure-core<2.0.0,>=1.11.0->azure-identity==1.12) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ping\\miniconda3\\envs\\gptold\\lib\\site-packages (from requests>=2.18.4->azure-core<2.0.0,>=1.11.0->azure-identity==1.12) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ping\\miniconda3\\envs\\gptold\\lib\\site-packages (from requests>=2.18.4->azure-core<2.0.0,>=1.11.0->azure-identity==1.12) (2023.11.17)\n",
      "Using cached cryptography-41.0.5-cp37-abi3-win_amd64.whl (2.7 MB)\n",
      "Using cached msal-1.25.0-py2.py3-none-any.whl (97 kB)\n",
      "Downloading cffi-1.16.0-cp310-cp310-win_amd64.whl (181 kB)\n",
      "   ---------------------------------------- 0.0/181.6 kB ? eta -:--:--\n",
      "   ------ -------------------------------- 30.7/181.6 kB 640.0 kB/s eta 0:00:01\n",
      "   -------------------- ------------------- 92.2/181.6 kB 1.7 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 112.6/181.6 kB 1.3 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 112.6/181.6 kB 1.3 MB/s eta 0:00:01\n",
      "   -------------------------------------- 181.6/181.6 kB 911.6 kB/s eta 0:00:00\n",
      "Using cached portalocker-2.8.2-py3-none-any.whl (17 kB)\n",
      "Using cached PyJWT-2.8.0-py3-none-any.whl (22 kB)\n",
      "Installing collected packages: PyJWT, pycparser, portalocker, cffi, cryptography, msal, msal-extensions, azure-identity\n",
      "Successfully installed PyJWT-2.8.0 azure-identity-1.12.0 cffi-1.16.0 cryptography-41.0.5 msal-1.25.0 msal-extensions-1.0.0 portalocker-2.8.2 pycparser-2.21\n"
     ]
    }
   ],
   "source": [
    "! pip install azure-search-documents==11.4.0b8 \n",
    "! pip install openai==0.28.1\n",
    "! pip install python-dotenv\n",
    "! pip install langchain==0.0.336\n",
    "! pip install tiktoken\n",
    "! pip install azure-identity==1.12"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores.azuresearch import AzureSearch"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure OpenAI settings\n",
    "Configure the OpenAI settings to use Azure OpenAI or OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure environment variables  \n",
    "os.environ[\"OPENAI_API_TYPE\"] = \"azure\"  \n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"AZURE_OPENAI_API_KEY\")  \n",
    "os.environ[\"OPENAI_API_BASE\"] = os.getenv(\"AZURE_OPENAI_ENDPOINT\")  \n",
    "os.environ[\"OPENAI_API_VERSION\"] = os.getenv(\"AZURE_OPENAI_API_VERSION\")  \n",
    "model: str = \"startping_embedding\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure vector store settings\n",
    " \n",
    "Set up the vector store settings using environment variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store_address: str = os.getenv(\"AZURE_SEARCH_CHARGE_ENDPOINT\")  \n",
    "vector_store_password: str = os.getenv(\"AZURE_SEARCH_CHARGE_API_KEY\") \n",
    "index_name: str = \"langchain-vector-demo_px\"\n",
    "embeddings: OpenAIEmbeddings = OpenAIEmbeddings(deployment=model, chunk_size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create embeddings and vector store instances\n",
    " \n",
    "Create instances of the OpenAIEmbeddings and AzureSearch classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidRequestError",
     "evalue": "Resource not found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidRequestError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mc:\\Repository\\azure\\azureai\\src\\azuresearch.ipynb Cell 11\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Repository/azure/azureai/src/azuresearch.ipynb#X13sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mazure\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mexceptions\u001b[39;00m \u001b[39mimport\u001b[39;00m HttpResponseError\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Repository/azure/azureai/src/azuresearch.ipynb#X13sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Repository/azure/azureai/src/azuresearch.ipynb#X13sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     vector_store \u001b[39m=\u001b[39m AzureSearch(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Repository/azure/azureai/src/azuresearch.ipynb#X13sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m         azure_search_endpoint\u001b[39m=\u001b[39;49mvector_store_address,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Repository/azure/azureai/src/azuresearch.ipynb#X13sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m         azure_search_key\u001b[39m=\u001b[39;49mvector_store_password,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Repository/azure/azureai/src/azuresearch.ipynb#X13sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m         index_name\u001b[39m=\u001b[39;49mindex_name,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Repository/azure/azureai/src/azuresearch.ipynb#X13sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m         embedding_function\u001b[39m=\u001b[39;49membeddings\u001b[39m.\u001b[39;49membed_query,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Repository/azure/azureai/src/azuresearch.ipynb#X13sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m         semantic_configuration_name\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mconfig\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Repository/azure/azureai/src/azuresearch.ipynb#X13sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m         semantic_settings\u001b[39m=\u001b[39;49mSemanticSettings(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Repository/azure/azureai/src/azuresearch.ipynb#X13sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m             default_configuration\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mconfig\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Repository/azure/azureai/src/azuresearch.ipynb#X13sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m             configurations\u001b[39m=\u001b[39;49m[\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Repository/azure/azureai/src/azuresearch.ipynb#X13sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m                 SemanticConfiguration(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Repository/azure/azureai/src/azuresearch.ipynb#X13sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m                     name\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mconfig\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Repository/azure/azureai/src/azuresearch.ipynb#X13sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m                     prioritized_fields\u001b[39m=\u001b[39;49mPrioritizedFields(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Repository/azure/azureai/src/azuresearch.ipynb#X13sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m                         title_field\u001b[39m=\u001b[39;49mSemanticField(field_name\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mcontent\u001b[39;49m\u001b[39m'\u001b[39;49m),\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Repository/azure/azureai/src/azuresearch.ipynb#X13sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m                         prioritized_content_fields\u001b[39m=\u001b[39;49m[SemanticField(field_name\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mcontent\u001b[39;49m\u001b[39m'\u001b[39;49m)],\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Repository/azure/azureai/src/azuresearch.ipynb#X13sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m                         prioritized_keywords_fields\u001b[39m=\u001b[39;49m[SemanticField(field_name\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mmetadata\u001b[39;49m\u001b[39m'\u001b[39;49m)]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Repository/azure/azureai/src/azuresearch.ipynb#X13sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m                     ))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Repository/azure/azureai/src/azuresearch.ipynb#X13sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m             ])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Repository/azure/azureai/src/azuresearch.ipynb#X13sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m     )\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Repository/azure/azureai/src/azuresearch.ipynb#X13sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m \u001b[39mexcept\u001b[39;00m HttpResponseError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Repository/azure/azureai/src/azuresearch.ipynb#X13sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mError details: \u001b[39m\u001b[39m{\u001b[39;00me\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Ping\\miniconda3\\envs\\gptold\\lib\\site-packages\\langchain\\vectorstores\\azuresearch.py:229\u001b[0m, in \u001b[0;36mAzureSearch.__init__\u001b[1;34m(self, azure_search_endpoint, azure_search_key, index_name, embedding_function, search_type, semantic_configuration_name, semantic_query_language, fields, vector_search, semantic_settings, scoring_profiles, default_scoring_profile, **kwargs)\u001b[0m\n\u001b[0;32m    212\u001b[0m \u001b[39m# Initialize base class\u001b[39;00m\n\u001b[0;32m    213\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membedding_function \u001b[39m=\u001b[39m embedding_function\n\u001b[0;32m    214\u001b[0m default_fields \u001b[39m=\u001b[39m [\n\u001b[0;32m    215\u001b[0m     SimpleField(\n\u001b[0;32m    216\u001b[0m         name\u001b[39m=\u001b[39mFIELDS_ID,\n\u001b[0;32m    217\u001b[0m         \u001b[39mtype\u001b[39m\u001b[39m=\u001b[39mSearchFieldDataType\u001b[39m.\u001b[39mString,\n\u001b[0;32m    218\u001b[0m         key\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m    219\u001b[0m         filterable\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m    220\u001b[0m     ),\n\u001b[0;32m    221\u001b[0m     SearchableField(\n\u001b[0;32m    222\u001b[0m         name\u001b[39m=\u001b[39mFIELDS_CONTENT,\n\u001b[0;32m    223\u001b[0m         \u001b[39mtype\u001b[39m\u001b[39m=\u001b[39mSearchFieldDataType\u001b[39m.\u001b[39mString,\n\u001b[0;32m    224\u001b[0m     ),\n\u001b[0;32m    225\u001b[0m     SearchField(\n\u001b[0;32m    226\u001b[0m         name\u001b[39m=\u001b[39mFIELDS_CONTENT_VECTOR,\n\u001b[0;32m    227\u001b[0m         \u001b[39mtype\u001b[39m\u001b[39m=\u001b[39mSearchFieldDataType\u001b[39m.\u001b[39mCollection(SearchFieldDataType\u001b[39m.\u001b[39mSingle),\n\u001b[0;32m    228\u001b[0m         searchable\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m--> 229\u001b[0m         vector_search_dimensions\u001b[39m=\u001b[39m\u001b[39mlen\u001b[39m(embedding_function(\u001b[39m\"\u001b[39;49m\u001b[39mText\u001b[39;49m\u001b[39m\"\u001b[39;49m)),\n\u001b[0;32m    230\u001b[0m         vector_search_configuration\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mdefault\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    231\u001b[0m     ),\n\u001b[0;32m    232\u001b[0m     SearchableField(\n\u001b[0;32m    233\u001b[0m         name\u001b[39m=\u001b[39mFIELDS_METADATA,\n\u001b[0;32m    234\u001b[0m         \u001b[39mtype\u001b[39m\u001b[39m=\u001b[39mSearchFieldDataType\u001b[39m.\u001b[39mString,\n\u001b[0;32m    235\u001b[0m     ),\n\u001b[0;32m    236\u001b[0m ]\n\u001b[0;32m    237\u001b[0m user_agent \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mlangchain\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    238\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39muser_agent\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m kwargs \u001b[39mand\u001b[39;00m kwargs[\u001b[39m\"\u001b[39m\u001b[39muser_agent\u001b[39m\u001b[39m\"\u001b[39m]:\n",
      "File \u001b[1;32mc:\\Users\\Ping\\miniconda3\\envs\\gptold\\lib\\site-packages\\langchain\\embeddings\\openai.py:584\u001b[0m, in \u001b[0;36mOpenAIEmbeddings.embed_query\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m    575\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39membed_query\u001b[39m(\u001b[39mself\u001b[39m, text: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m List[\u001b[39mfloat\u001b[39m]:\n\u001b[0;32m    576\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Call out to OpenAI's embedding endpoint for embedding query text.\u001b[39;00m\n\u001b[0;32m    577\u001b[0m \n\u001b[0;32m    578\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    582\u001b[0m \u001b[39m        Embedding for the text.\u001b[39;00m\n\u001b[0;32m    583\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 584\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49membed_documents([text])[\u001b[39m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Ping\\miniconda3\\envs\\gptold\\lib\\site-packages\\langchain\\embeddings\\openai.py:555\u001b[0m, in \u001b[0;36mOpenAIEmbeddings.embed_documents\u001b[1;34m(self, texts, chunk_size)\u001b[0m\n\u001b[0;32m    552\u001b[0m \u001b[39m# NOTE: to keep things simple, we assume the list may contain texts longer\u001b[39;00m\n\u001b[0;32m    553\u001b[0m \u001b[39m#       than the maximum context and use length-safe embedding function.\u001b[39;00m\n\u001b[0;32m    554\u001b[0m engine \u001b[39m=\u001b[39m cast(\u001b[39mstr\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdeployment)\n\u001b[1;32m--> 555\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_len_safe_embeddings(texts, engine\u001b[39m=\u001b[39;49mengine)\n",
      "File \u001b[1;32mc:\\Users\\Ping\\miniconda3\\envs\\gptold\\lib\\site-packages\\langchain\\embeddings\\openai.py:431\u001b[0m, in \u001b[0;36mOpenAIEmbeddings._get_len_safe_embeddings\u001b[1;34m(self, texts, engine, chunk_size)\u001b[0m\n\u001b[0;32m    428\u001b[0m     _iter \u001b[39m=\u001b[39m \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m, \u001b[39mlen\u001b[39m(tokens), _chunk_size)\n\u001b[0;32m    430\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m _iter:\n\u001b[1;32m--> 431\u001b[0m     response \u001b[39m=\u001b[39m embed_with_retry(\n\u001b[0;32m    432\u001b[0m         \u001b[39mself\u001b[39m,\n\u001b[0;32m    433\u001b[0m         \u001b[39minput\u001b[39m\u001b[39m=\u001b[39mtokens[i : i \u001b[39m+\u001b[39m _chunk_size],\n\u001b[0;32m    434\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_invocation_params,\n\u001b[0;32m    435\u001b[0m     )\n\u001b[0;32m    436\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(response, \u001b[39mdict\u001b[39m):\n\u001b[0;32m    437\u001b[0m         response \u001b[39m=\u001b[39m response\u001b[39m.\u001b[39mdict()\n",
      "File \u001b[1;32mc:\\Users\\Ping\\miniconda3\\envs\\gptold\\lib\\site-packages\\langchain\\embeddings\\openai.py:114\u001b[0m, in \u001b[0;36membed_with_retry\u001b[1;34m(embeddings, **kwargs)\u001b[0m\n\u001b[0;32m    111\u001b[0m     response \u001b[39m=\u001b[39m embeddings\u001b[39m.\u001b[39mclient\u001b[39m.\u001b[39mcreate(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    112\u001b[0m     \u001b[39mreturn\u001b[39;00m _check_response(response, skip_empty\u001b[39m=\u001b[39membeddings\u001b[39m.\u001b[39mskip_empty)\n\u001b[1;32m--> 114\u001b[0m \u001b[39mreturn\u001b[39;00m _embed_with_retry(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Ping\\miniconda3\\envs\\gptold\\lib\\site-packages\\tenacity\\__init__.py:289\u001b[0m, in \u001b[0;36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[1;34m(*args, **kw)\u001b[0m\n\u001b[0;32m    287\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(f)\n\u001b[0;32m    288\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped_f\u001b[39m(\u001b[39m*\u001b[39margs: t\u001b[39m.\u001b[39mAny, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw: t\u001b[39m.\u001b[39mAny) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m t\u001b[39m.\u001b[39mAny:\n\u001b[1;32m--> 289\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m(f, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw)\n",
      "File \u001b[1;32mc:\\Users\\Ping\\miniconda3\\envs\\gptold\\lib\\site-packages\\tenacity\\__init__.py:379\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[1;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m    377\u001b[0m retry_state \u001b[39m=\u001b[39m RetryCallState(retry_object\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m, fn\u001b[39m=\u001b[39mfn, args\u001b[39m=\u001b[39margs, kwargs\u001b[39m=\u001b[39mkwargs)\n\u001b[0;32m    378\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m--> 379\u001b[0m     do \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49miter(retry_state\u001b[39m=\u001b[39;49mretry_state)\n\u001b[0;32m    380\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(do, DoAttempt):\n\u001b[0;32m    381\u001b[0m         \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Ping\\miniconda3\\envs\\gptold\\lib\\site-packages\\tenacity\\__init__.py:314\u001b[0m, in \u001b[0;36mBaseRetrying.iter\u001b[1;34m(self, retry_state)\u001b[0m\n\u001b[0;32m    312\u001b[0m is_explicit_retry \u001b[39m=\u001b[39m fut\u001b[39m.\u001b[39mfailed \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(fut\u001b[39m.\u001b[39mexception(), TryAgain)\n\u001b[0;32m    313\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (is_explicit_retry \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mretry(retry_state)):\n\u001b[1;32m--> 314\u001b[0m     \u001b[39mreturn\u001b[39;00m fut\u001b[39m.\u001b[39;49mresult()\n\u001b[0;32m    316\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mafter \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    317\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mafter(retry_state)\n",
      "File \u001b[1;32mc:\\Users\\Ping\\miniconda3\\envs\\gptold\\lib\\concurrent\\futures\\_base.py:451\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    449\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n\u001b[0;32m    450\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[1;32m--> 451\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__get_result()\n\u001b[0;32m    453\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_condition\u001b[39m.\u001b[39mwait(timeout)\n\u001b[0;32m    455\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[1;32mc:\\Users\\Ping\\miniconda3\\envs\\gptold\\lib\\concurrent\\futures\\_base.py:403\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    401\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception:\n\u001b[0;32m    402\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 403\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception\n\u001b[0;32m    404\u001b[0m     \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    405\u001b[0m         \u001b[39m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[0;32m    406\u001b[0m         \u001b[39mself\u001b[39m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Ping\\miniconda3\\envs\\gptold\\lib\\site-packages\\tenacity\\__init__.py:382\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[1;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m    380\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(do, DoAttempt):\n\u001b[0;32m    381\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 382\u001b[0m         result \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    383\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m:  \u001b[39m# noqa: B902\u001b[39;00m\n\u001b[0;32m    384\u001b[0m         retry_state\u001b[39m.\u001b[39mset_exception(sys\u001b[39m.\u001b[39mexc_info())  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Ping\\miniconda3\\envs\\gptold\\lib\\site-packages\\langchain\\embeddings\\openai.py:111\u001b[0m, in \u001b[0;36membed_with_retry.<locals>._embed_with_retry\u001b[1;34m(**kwargs)\u001b[0m\n\u001b[0;32m    109\u001b[0m \u001b[39m@retry_decorator\u001b[39m\n\u001b[0;32m    110\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_embed_with_retry\u001b[39m(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[1;32m--> 111\u001b[0m     response \u001b[39m=\u001b[39m embeddings\u001b[39m.\u001b[39mclient\u001b[39m.\u001b[39mcreate(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    112\u001b[0m     \u001b[39mreturn\u001b[39;00m _check_response(response, skip_empty\u001b[39m=\u001b[39membeddings\u001b[39m.\u001b[39mskip_empty)\n",
      "File \u001b[1;32mc:\\Users\\Ping\\miniconda3\\envs\\gptold\\lib\\site-packages\\openai\\api_resources\\embedding.py:33\u001b[0m, in \u001b[0;36mEmbedding.create\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m     32\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 33\u001b[0m         response \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mcreate(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     35\u001b[0m         \u001b[39m# If a user specifies base64, we'll just return the encoded string.\u001b[39;00m\n\u001b[0;32m     36\u001b[0m         \u001b[39m# This is only for the default case.\u001b[39;00m\n\u001b[0;32m     37\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m user_provided_encoding_format:\n",
      "File \u001b[1;32mc:\\Users\\Ping\\miniconda3\\envs\\gptold\\lib\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py:155\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[1;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[0;32m    130\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate\u001b[39m(\n\u001b[0;32m    131\u001b[0m     \u001b[39mcls\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    138\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams,\n\u001b[0;32m    139\u001b[0m ):\n\u001b[0;32m    140\u001b[0m     (\n\u001b[0;32m    141\u001b[0m         deployment_id,\n\u001b[0;32m    142\u001b[0m         engine,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    152\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams\n\u001b[0;32m    153\u001b[0m     )\n\u001b[1;32m--> 155\u001b[0m     response, _, api_key \u001b[39m=\u001b[39m requestor\u001b[39m.\u001b[39;49mrequest(\n\u001b[0;32m    156\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mpost\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    157\u001b[0m         url,\n\u001b[0;32m    158\u001b[0m         params\u001b[39m=\u001b[39;49mparams,\n\u001b[0;32m    159\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[0;32m    160\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[0;32m    161\u001b[0m         request_id\u001b[39m=\u001b[39;49mrequest_id,\n\u001b[0;32m    162\u001b[0m         request_timeout\u001b[39m=\u001b[39;49mrequest_timeout,\n\u001b[0;32m    163\u001b[0m     )\n\u001b[0;32m    165\u001b[0m     \u001b[39mif\u001b[39;00m stream:\n\u001b[0;32m    166\u001b[0m         \u001b[39m# must be an iterator\u001b[39;00m\n\u001b[0;32m    167\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[1;32mc:\\Users\\Ping\\miniconda3\\envs\\gptold\\lib\\site-packages\\openai\\api_requestor.py:299\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[1;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[0;32m    278\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\n\u001b[0;32m    279\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    280\u001b[0m     method,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    287\u001b[0m     request_timeout: Optional[Union[\u001b[39mfloat\u001b[39m, Tuple[\u001b[39mfloat\u001b[39m, \u001b[39mfloat\u001b[39m]]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    288\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[39mbool\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[0;32m    289\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequest_raw(\n\u001b[0;32m    290\u001b[0m         method\u001b[39m.\u001b[39mlower(),\n\u001b[0;32m    291\u001b[0m         url,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    297\u001b[0m         request_timeout\u001b[39m=\u001b[39mrequest_timeout,\n\u001b[0;32m    298\u001b[0m     )\n\u001b[1;32m--> 299\u001b[0m     resp, got_stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response(result, stream)\n\u001b[0;32m    300\u001b[0m     \u001b[39mreturn\u001b[39;00m resp, got_stream, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_key\n",
      "File \u001b[1;32mc:\\Users\\Ping\\miniconda3\\envs\\gptold\\lib\\site-packages\\openai\\api_requestor.py:710\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[1;34m(self, result, stream)\u001b[0m\n\u001b[0;32m    702\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m    703\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_interpret_response_line(\n\u001b[0;32m    704\u001b[0m             line, result\u001b[39m.\u001b[39mstatus_code, result\u001b[39m.\u001b[39mheaders, stream\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    705\u001b[0m         )\n\u001b[0;32m    706\u001b[0m         \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m parse_stream(result\u001b[39m.\u001b[39miter_lines())\n\u001b[0;32m    707\u001b[0m     ), \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    708\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    709\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m--> 710\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response_line(\n\u001b[0;32m    711\u001b[0m             result\u001b[39m.\u001b[39;49mcontent\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m    712\u001b[0m             result\u001b[39m.\u001b[39;49mstatus_code,\n\u001b[0;32m    713\u001b[0m             result\u001b[39m.\u001b[39;49mheaders,\n\u001b[0;32m    714\u001b[0m             stream\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    715\u001b[0m         ),\n\u001b[0;32m    716\u001b[0m         \u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    717\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Ping\\miniconda3\\envs\\gptold\\lib\\site-packages\\openai\\api_requestor.py:775\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[1;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[0;32m    773\u001b[0m stream_error \u001b[39m=\u001b[39m stream \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39merror\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m resp\u001b[39m.\u001b[39mdata\n\u001b[0;32m    774\u001b[0m \u001b[39mif\u001b[39;00m stream_error \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39m200\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m rcode \u001b[39m<\u001b[39m \u001b[39m300\u001b[39m:\n\u001b[1;32m--> 775\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_error_response(\n\u001b[0;32m    776\u001b[0m         rbody, rcode, resp\u001b[39m.\u001b[39mdata, rheaders, stream_error\u001b[39m=\u001b[39mstream_error\n\u001b[0;32m    777\u001b[0m     )\n\u001b[0;32m    778\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "\u001b[1;31mInvalidRequestError\u001b[0m: Resource not found"
     ]
    }
   ],
   "source": [
    "from azure.search.documents.indexes.models import (\n",
    "    SemanticSettings,\n",
    "    SemanticConfiguration,\n",
    "    PrioritizedFields,\n",
    "    SemanticField\n",
    ")\n",
    "from azure.core.exceptions import HttpResponseError\n",
    "\n",
    "try:\n",
    "    vector_store = AzureSearch(\n",
    "        azure_search_endpoint=vector_store_address,\n",
    "        azure_search_key=vector_store_password,\n",
    "        index_name=index_name,\n",
    "        embedding_function=embeddings.embed_query,\n",
    "        semantic_configuration_name='config',\n",
    "        semantic_settings=SemanticSettings(\n",
    "            default_configuration='config',\n",
    "            configurations=[\n",
    "                SemanticConfiguration(\n",
    "                    name='config',\n",
    "                    prioritized_fields=PrioritizedFields(\n",
    "                        title_field=SemanticField(field_name='content'),\n",
    "                        prioritized_content_fields=[SemanticField(field_name='content')],\n",
    "                        prioritized_keywords_fields=[SemanticField(field_name='metadata')]\n",
    "                    ))\n",
    "            ])\n",
    "    )\n",
    "except HttpResponseError as e:\n",
    "    print(f\"Error details: {e}\")\n",
    "    # Additional error handling or logging can be added here.\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insert text and embeddings into vector store\n",
    " \n",
    "Add texts and metadata from the JSON data to the vector store:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NDM5ODhjMmMtYzVkNC00MTkzLWIzMDktYjk5MzVhYTRmMWYx',\n",
       " 'N2YzOWEyYjktZjEyNS00ZTRhLTljNDYtMDdmZGEwNmNkYzg2',\n",
       " 'ZTY3ZjNjNmYtODIwYS00ZWI5LWExZmItZGQyMGYzODMyNGY1',\n",
       " 'ZmUyNmI1NTMtMTFiNy00OTQwLTk2OWItYWI2MmVlN2YyYTU4',\n",
       " 'YTJlZTE0MzctMGU0MS00ZWJhLWI2MjYtYWFiMjE5ZTFjMTQ0',\n",
       " 'NzQzZmE1OWEtYWMxZi00OWY2LThlZTUtNDBlYmE1MjBjODkx',\n",
       " 'MGFhMTg0ZjQtM2Y3NS00N2MwLTk5MGItM2I4OWEyZjRhMzY5',\n",
       " 'ZTk1ODgwZWEtNmMyYy00MjFmLTg2YWUtYWRiOWVhN2NmMTJk',\n",
       " 'ZjEzYTYzNzktODg2My00ODIzLWE3OGItNzk3MWQ1Yjc1NDc0',\n",
       " 'YmYyMDNjYzEtYTVmZS00M2FjLTk3NDEtZDNiZTg2NTgyY2Y1',\n",
       " 'YWM1OTJmYWItNjE4YS00ZmQ3LThhZTItZDg1MDA4OGJlZTNm',\n",
       " 'MWNjNDg4MzMtYzNiNC00NTU4LTlhYTgtOTkyZjJhZDhjNjEy',\n",
       " 'ODNhYWVlMmMtMmRmMi00NjRiLWI0ZDUtYmMyZjFiZDliZjZk',\n",
       " 'MjA3N2RiNzgtYTk1Zi00MWNkLTk5YjQtN2ZkYmJhMGM3M2M3',\n",
       " 'NTk3Yzg3OGUtZWMyYy00OGVmLTg5MGEtZjRhNTVlNmQ1NDQ2',\n",
       " 'NzdlY2RkZTItMzkwYi00NDRkLWE2NmMtMmI5NjMxOTYzMmRj',\n",
       " 'OWU4YjcyYzktZDU0MC00NjQwLWI2YmYtMjdiMTZhMmFiZjFl',\n",
       " 'NzFiYjEzN2QtMWY3OS00NmVkLTgzYTQtZjUyZWFkYTY4MDBl',\n",
       " 'MzZiMDI3MzktNzVlZi00NTM4LTgxYWEtMzM1NzJiMmM0YTI3',\n",
       " 'NTQwODMzZWUtNmZiNC00YmQxLWJhZjUtNWQ4NmRlMmEzZDll',\n",
       " 'YzQ0Mjk2NmUtMjFiMC00YjdkLWEwNjctMWNhYTY5YmFmODQ4',\n",
       " 'NWZjMDVlOTEtY2FmOC00NTg1LTgxZDYtMGFkODljMTE5MjVi',\n",
       " 'NjU1ZjNlZTMtMDg5Yi00YTczLTk5ZTEtMDUyODMyMGUyOTUy',\n",
       " 'NGE0M2Y4OTAtOTI1My00ZGUzLWJhOGMtNjU4Yzg0ZmE1MTU2',\n",
       " 'NTg1MGY1ZTEtZDk5YS00YmRlLWJhYTUtODk3OTMzY2NjNmFl',\n",
       " 'OGNhZGRlYWYtMzFiMy00YjYxLTk0YjUtNTIxZTU5MDYzNWEw',\n",
       " 'YmZhNDI5ZjMtZGU5Mi00NDgwLWJmODctZDlkZGJlNTdiNzYz',\n",
       " 'OTI1Mzk0MjctMmQ0Yi00NjdlLThiMTAtYWYwYjU2MTgzZWUw',\n",
       " 'YTA0ZGViY2ItYjc0Ny00ODQwLTliZjEtN2EzZGI4ZWQzY2Ex',\n",
       " 'OTNiZmI5ZDgtMDdjZi00MTA0LTg4MzMtNGE4M2I0ZDRjMWNk',\n",
       " 'NGVlNGFkY2QtOTZjNC00NGRhLWFlNDUtMTQ4MzM0ZmY1MWZl',\n",
       " 'OTcyMDBhYzAtNTQ2Yi00OGYyLWJiNjItMTkxODJlNDQ4MDkz',\n",
       " 'OTRhZDMwMDAtNmYyNy00N2IyLWFkNTEtNzE3MTc3MTNhZjNl',\n",
       " 'NmE2Mzc3ZTgtMmRmZC00NTQyLTg4MDQtNDMyZTQzZDlhOTFh',\n",
       " 'Njc3YTQwYTYtNTZjMS00MGFhLWJhOGQtMzRiZGQwY2Q2ZjEz',\n",
       " 'MWRhMzE3MDYtMWMxNS00Y2FhLWFhMTMtOWFiN2YwOWUxYzYw',\n",
       " 'MzExMDk1YTUtMDBlNC00MDJjLWJkZjctNzhkMTU5YTA5NzJi',\n",
       " 'ODcyMjAyMjItZDBiZi00NjQzLWI5MWEtNzNkMGQyOWNhNWUw',\n",
       " 'MjUxZTJhNjYtZjk0MC00Yjg2LWExY2UtMTM0ZWM3MTMwYWUz',\n",
       " 'Nzg1MDdlMTQtZGNkOC00NzU3LTk1MDUtZThmNzY3YWQzMDM2',\n",
       " 'Y2E0MTRmODUtMzI0OS00NmFmLWIwNjQtZmI4NzI2NzU3OTU5',\n",
       " 'ZDZmMGQ0M2ItYzZmYi00ZGIyLWJlNWYtMjAxNzMzZWQ0MDgy']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "loader = TextLoader(\"../data/txt/state_of_the_union.txt\", encoding=\"utf-8\")\n",
    "\n",
    "documents = loader.load()\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "docs = text_splitter.split_documents(documents)\n",
    "\n",
    "vector_store.add_documents(documents=docs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform a vector similarity search\n",
    " \n",
    "Execute a pure vector similarity search using the similarity_search() method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tonight. I call on the Senate to: Pass the Freedom to Vote Act. Pass the John Lewis Voting Rights Act. And while you’re at it, pass the Disclose Act so Americans can know who is funding our elections. \n",
      "\n",
      "Tonight, I’d like to honor someone who has dedicated his life to serve this country: Justice Stephen Breyer—an Army veteran, Constitutional scholar, and retiring Justice of the United States Supreme Court. Justice Breyer, thank you for your service. \n",
      "\n",
      "One of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court. \n",
      "\n",
      "And I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson. One of our nation’s top legal minds, who will continue Justice Breyer’s legacy of excellence.\n"
     ]
    }
   ],
   "source": [
    "# Perform a similarity search\n",
    "docs = vector_store.similarity_search(\n",
    "    query=\"What did the president say about Ketanji Brown Jackson\",\n",
    "    k=3,\n",
    "    search_type=\"similarity\",\n",
    ")\n",
    "print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform a vector similarity search with relevance scores\n",
    " \n",
    "Execute a pure vector similarity search using the similarity_search_with_relevance_scores() method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(Document(page_content='Tonight. I call on the Senate to: Pass the Freedom to Vote Act. Pass the John Lewis Voting Rights Act. And while you’re at it, pass the Disclose Act so Americans can know who is funding our elections. \\n\\nTonight, I’d like to honor someone who has dedicated his life to serve this country: Justice Stephen Breyer—an Army veteran, Constitutional scholar, and retiring Justice of the United States Supreme Court. Justice Breyer, thank you for your service. \\n\\nOne of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court. \\n\\nAnd I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson. One of our nation’s top legal minds, who will continue Justice Breyer’s legacy of excellence.', metadata={'source': '../data/txt/state_of_the_union.txt'}),\n",
      "  0.8441472),\n",
      " (Document(page_content='A former top litigator in private practice. A former federal public defender. And from a family of public school educators and police officers. A consensus builder. Since she’s been nominated, she’s received a broad range of support—from the Fraternal Order of Police to former judges appointed by Democrats and Republicans. \\n\\nAnd if we are to advance liberty and justice, we need to secure the Border and fix the immigration system. \\n\\nWe can do both. At our border, we’ve installed new technology like cutting-edge scanners to better detect drug smuggling.  \\n\\nWe’ve set up joint patrols with Mexico and Guatemala to catch more human traffickers.  \\n\\nWe’re putting in place dedicated immigration judges so families fleeing persecution and violence can have their cases heard faster. \\n\\nWe’re securing commitments and supporting partners in South and Central America to host more refugees and secure their own borders.', metadata={'source': '../data/txt/state_of_the_union.txt'}),\n",
      "  0.82153815),\n",
      " (Document(page_content='And for our LGBTQ+ Americans, let’s finally get the bipartisan Equality Act to my desk. The onslaught of state laws targeting transgender Americans and their families is wrong. \\n\\nAs I said last year, especially to our younger transgender Americans, I will always have your back as your President, so you can be yourself and reach your God-given potential. \\n\\nWhile it often appears that we never agree, that isn’t true. I signed 80 bipartisan bills into law last year. From preventing government shutdowns to protecting Asian-Americans from still-too-common hate crimes to reforming military justice. \\n\\nAnd soon, we’ll strengthen the Violence Against Women Act that I first wrote three decades ago. It is important for us to show the nation that we can come together and do big things. \\n\\nSo tonight I’m offering a Unity Agenda for the Nation. Four big things we can do together.  \\n\\nFirst, beat the opioid epidemic.', metadata={'source': '../data/txt/state_of_the_union.txt'}),\n",
      "  0.8155073),\n",
      " (Document(page_content='Tonight, I’m announcing a crackdown on these companies overcharging American businesses and consumers. \\n\\nAnd as Wall Street firms take over more nursing homes, quality in those homes has gone down and costs have gone up.  \\n\\nThat ends on my watch. \\n\\nMedicare is going to set higher standards for nursing homes and make sure your loved ones get the care they deserve and expect. \\n\\nWe’ll also cut costs and keep the economy going strong by giving workers a fair shot, provide more training and apprenticeships, hire them based on their skills not degrees. \\n\\nLet’s pass the Paycheck Fairness Act and paid leave.  \\n\\nRaise the minimum wage to $15 an hour and extend the Child Tax Credit, so no one has to raise a family in poverty. \\n\\nLet’s increase Pell Grants and increase our historic support of HBCUs, and invest in what Jill—our First Lady who teaches full-time—calls America’s best-kept secret: community colleges.', metadata={'source': '../data/txt/state_of_the_union.txt'}),\n",
      "  0.8154307)]\n"
     ]
    }
   ],
   "source": [
    "docs_and_scores = vector_store.similarity_search_with_relevance_scores(\n",
    "    query=\"What did the president say about Ketanji Brown Jackson\",\n",
    "    k=4,\n",
    "    score_threshold=0.80,\n",
    ")\n",
    "from pprint import pprint\n",
    "\n",
    "pprint(docs_and_scores)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform a Hybrid Search\n",
    "\n",
    "Execute hybrid search using the search_type or hybrid_search() method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tonight. I call on the Senate to: Pass the Freedom to Vote Act. Pass the John Lewis Voting Rights Act. And while you’re at it, pass the Disclose Act so Americans can know who is funding our elections. \n",
      "\n",
      "Tonight, I’d like to honor someone who has dedicated his life to serve this country: Justice Stephen Breyer—an Army veteran, Constitutional scholar, and retiring Justice of the United States Supreme Court. Justice Breyer, thank you for your service. \n",
      "\n",
      "One of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court. \n",
      "\n",
      "And I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson. One of our nation’s top legal minds, who will continue Justice Breyer’s legacy of excellence.\n"
     ]
    }
   ],
   "source": [
    "# Perform a hybrid search\n",
    "docs = vector_store.similarity_search(\n",
    "    query=\"What did the president say about Ketanji Brown Jackson\",\n",
    "    k=3,\n",
    "    search_type=\"hybrid\",\n",
    ")\n",
    "print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tonight. I call on the Senate to: Pass the Freedom to Vote Act. Pass the John Lewis Voting Rights Act. And while you’re at it, pass the Disclose Act so Americans can know who is funding our elections. \n",
      "\n",
      "Tonight, I’d like to honor someone who has dedicated his life to serve this country: Justice Stephen Breyer—an Army veteran, Constitutional scholar, and retiring Justice of the United States Supreme Court. Justice Breyer, thank you for your service. \n",
      "\n",
      "One of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court. \n",
      "\n",
      "And I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson. One of our nation’s top legal minds, who will continue Justice Breyer’s legacy of excellence.\n"
     ]
    }
   ],
   "source": [
    "# Perform a hybrid search\n",
    "docs = vector_store.hybrid_search(\n",
    "    query=\"What did the president say about Ketanji Brown Jackson\", k=3\n",
    ")\n",
    "print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a new index with custom filterable fields "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.search.documents.indexes.models import (\n",
    "    ScoringProfile,\n",
    "    SearchableField,\n",
    "    SearchField,\n",
    "    SearchFieldDataType,\n",
    "    SimpleField,\n",
    "    TextWeights,\n",
    ")\n",
    "\n",
    "embeddings: OpenAIEmbeddings = OpenAIEmbeddings(deployment=model, chunk_size=1)\n",
    "embedding_function = embeddings.embed_query\n",
    "\n",
    "fields = [\n",
    "    SimpleField(\n",
    "        name=\"id\",\n",
    "        type=SearchFieldDataType.String,\n",
    "        key=True,\n",
    "        filterable=True,\n",
    "    ),\n",
    "    SearchableField(\n",
    "        name=\"content\",\n",
    "        type=SearchFieldDataType.String,\n",
    "        searchable=True,\n",
    "    ),\n",
    "    SearchField(\n",
    "        name=\"content_vector\",\n",
    "        type=SearchFieldDataType.Collection(SearchFieldDataType.Single),\n",
    "        searchable=True,\n",
    "        vector_search_dimensions=len(embedding_function(\"Text\")),\n",
    "        vector_search_configuration=\"default\",\n",
    "    ),\n",
    "    SearchableField(\n",
    "        name=\"metadata\",\n",
    "        type=SearchFieldDataType.String,\n",
    "        searchable=True,\n",
    "    ),\n",
    "    # Additional field to store the title\n",
    "    SearchableField(\n",
    "        name=\"title\",\n",
    "        type=SearchFieldDataType.String,\n",
    "        searchable=True,\n",
    "    ),\n",
    "    # Additional field for filtering on document source\n",
    "    SimpleField(\n",
    "        name=\"source\",\n",
    "        type=SearchFieldDataType.String,\n",
    "        filterable=True,\n",
    "    ),\n",
    "]\n",
    "\n",
    "index_name: str = \"langchain-vector-demo-custom\"\n",
    "\n",
    "vector_store: AzureSearch = AzureSearch(\n",
    "    azure_search_endpoint=vector_store_address,\n",
    "    azure_search_key=vector_store_password,\n",
    "    index_name=index_name,\n",
    "    embedding_function=embedding_function,\n",
    "    fields=fields,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform a query with a custom filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ZTJlNGM0MTUtMGZmNS00NWFhLWE4YjktMzQyZWE2NWQ3M2Rj',\n",
       " 'MDNmMTRmMGYtMTA4MC00NjM5LTgxZWEtNWY3N2U1MDVhYWQ5',\n",
       " 'MWJmY2VjNzEtYzQxNS00MTA4LWI4ZTctOTI3OWRjZTMwOTI2']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data in the metadata dictionary with a corresponding field in the index will be added to the index\n",
    "# In this example, the metadata dictionary contains a title, a source and a random field\n",
    "# The title and the source will be added to the index as separate fields, but the random won't. (as it is not defined in the fields list)\n",
    "# The random field will be only stored in the metadata field\n",
    "vector_store.add_texts(\n",
    "    [\"Test 1\", \"Test 2\", \"Test 3\"],\n",
    "    [\n",
    "        {\"title\": \"Title 1\", \"source\": \"A\", \"random\": \"10290\"},\n",
    "        {\"title\": \"Title 2\", \"source\": \"A\", \"random\": \"48392\"},\n",
    "        {\"title\": \"Title 3\", \"source\": \"B\", \"random\": \"32893\"},\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Test 3', metadata={'title': 'Title 3', 'source': 'B', 'random': '32893'}),\n",
       " Document(page_content='Test 1', metadata={'title': 'Title 1', 'source': 'A', 'random': '10290'}),\n",
       " Document(page_content='Test 2', metadata={'title': 'Title 2', 'source': 'A', 'random': '48392'})]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = vector_store.similarity_search(query=\"Test 3 source1\", k=3, search_type=\"hybrid\")\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Test 1', metadata={'title': 'Title 1', 'source': 'A', 'random': '10290'}),\n",
       " Document(page_content='Test 2', metadata={'title': 'Title 2', 'source': 'A', 'random': '48392'})]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = vector_store.similarity_search(\n",
    "    query=\"Test 3 source1\", k=3, search_type=\"hybrid\", filters=\"source eq 'A'\"\n",
    ")\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a new index with a Scoring Profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.search.documents.indexes.models import (\n",
    "    FreshnessScoringFunction,\n",
    "    FreshnessScoringParameters,\n",
    "    ScoringProfile,\n",
    "    SearchableField,\n",
    "    SearchField,\n",
    "    SearchFieldDataType,\n",
    "    SimpleField,\n",
    "    TextWeights,\n",
    ")\n",
    "\n",
    "embeddings: OpenAIEmbeddings = OpenAIEmbeddings(deployment=model, chunk_size=1)\n",
    "embedding_function = embeddings.embed_query\n",
    "\n",
    "fields = [\n",
    "    SimpleField(\n",
    "        name=\"id\",\n",
    "        type=SearchFieldDataType.String,\n",
    "        key=True,\n",
    "        filterable=True,\n",
    "    ),\n",
    "    SearchableField(\n",
    "        name=\"content\",\n",
    "        type=SearchFieldDataType.String,\n",
    "        searchable=True,\n",
    "    ),\n",
    "    SearchField(\n",
    "        name=\"content_vector\",\n",
    "        type=SearchFieldDataType.Collection(SearchFieldDataType.Single),\n",
    "        searchable=True,\n",
    "        vector_search_dimensions=len(embedding_function(\"Text\")),\n",
    "        vector_search_configuration=\"default\",\n",
    "    ),\n",
    "    SearchableField(\n",
    "        name=\"metadata\",\n",
    "        type=SearchFieldDataType.String,\n",
    "        searchable=True,\n",
    "    ),\n",
    "    # Additional field to store the title\n",
    "    SearchableField(\n",
    "        name=\"title\",\n",
    "        type=SearchFieldDataType.String,\n",
    "        searchable=True,\n",
    "    ),\n",
    "    # Additional field for filtering on document source\n",
    "    SimpleField(\n",
    "        name=\"source\",\n",
    "        type=SearchFieldDataType.String,\n",
    "        filterable=True,\n",
    "    ),\n",
    "    # Additional data field for last doc update\n",
    "    SimpleField(\n",
    "        name=\"last_update\",\n",
    "        type=SearchFieldDataType.DateTimeOffset,\n",
    "        searchable=True,\n",
    "        filterable=True,\n",
    "    ),\n",
    "]\n",
    "# Adding a custom scoring profile with a freshness function\n",
    "sc_name = \"scoring_profile\"\n",
    "sc = ScoringProfile(\n",
    "    name=sc_name,\n",
    "    text_weights=TextWeights(weights={\"title\": 5}),\n",
    "    function_aggregation=\"sum\",\n",
    "    functions=[\n",
    "        FreshnessScoringFunction(\n",
    "            field_name=\"last_update\",\n",
    "            boost=100,\n",
    "            parameters=FreshnessScoringParameters(boosting_duration=\"P2D\"),\n",
    "            interpolation=\"linear\",\n",
    "        )\n",
    "    ],\n",
    ")\n",
    "\n",
    "index_name = \"langchain-vector-demo-custom-scoring-profile\"\n",
    "\n",
    "vector_store: AzureSearch = AzureSearch(\n",
    "    azure_search_endpoint=vector_store_address,\n",
    "    azure_search_key=vector_store_password,\n",
    "    index_name=index_name,\n",
    "    embedding_function=embeddings.embed_query,\n",
    "    fields=fields,\n",
    "    scoring_profiles=[sc],\n",
    "    default_scoring_profile=sc_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['N2U5OThiYTMtNzU1OS00NzhmLTkzY2UtMzdmZTFkOWQzMTEx',\n",
       " 'ZjEwZmI0YmUtMjgyYS00MTJlLWI0ZmMtMjY1MGI2YjE1NDk1',\n",
       " 'MWIyZDM1NzYtYTVkYy00NWE0LWFkN2ItNmRmOGQyMDFmNTBj']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adding same data with different last_update to show Scoring Profile effect\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "today = datetime.utcnow().strftime(\"%Y-%m-%dT%H:%M:%S-00:00\")\n",
    "yesterday = (datetime.utcnow() - timedelta(days=1)).strftime(\"%Y-%m-%dT%H:%M:%S-00:00\")\n",
    "one_month_ago = (datetime.utcnow() - timedelta(days=30)).strftime(\n",
    "    \"%Y-%m-%dT%H:%M:%S-00:00\"\n",
    ")\n",
    "\n",
    "vector_store.add_texts(\n",
    "    [\"Test 1\", \"Test 1\", \"Test 1\"],\n",
    "    [\n",
    "        {\n",
    "            \"title\": \"Title 1\",\n",
    "            \"source\": \"source1\",\n",
    "            \"random\": \"10290\",\n",
    "            \"last_update\": today,\n",
    "        },\n",
    "        {\n",
    "            \"title\": \"Title 1\",\n",
    "            \"source\": \"source1\",\n",
    "            \"random\": \"48392\",\n",
    "            \"last_update\": yesterday,\n",
    "        },\n",
    "        {\n",
    "            \"title\": \"Title 1\",\n",
    "            \"source\": \"source1\",\n",
    "            \"random\": \"32893\",\n",
    "            \"last_update\": one_month_ago,\n",
    "        },\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Test 1', metadata={'title': 'Title 1', 'source': 'source1', 'random': '32893', 'last_update': '2023-10-22T15:25:08-00:00'}),\n",
       " Document(page_content='Test 1', metadata={'title': 'Title 1', 'source': 'source1', 'random': '48392', 'last_update': '2023-11-20T15:25:08-00:00'}),\n",
       " Document(page_content='Test 1', metadata={'title': 'Title 1', 'source': 'source1', 'random': '10290', 'last_update': '2023-11-21T15:25:08-00:00'})]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = vector_store.similarity_search(query=\"Test 1\", k=3, search_type=\"similarity\")\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "645053d6307d413a1a75681b5ebb6449bb2babba4bcb0bf65a1ddc3dbefb108a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

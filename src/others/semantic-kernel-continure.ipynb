{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multiple Results\n",
    "In this notebook we show how you can in a single request, have the LLM model return multiple results per prompt. This is useful for running experiments where you want to evaluate the robustness of your prompt and the parameters of your config against a particular large language model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please ensure that torch and transformers are installed to use HuggingFaceTextCompletion\n",
    "# ! pip install torch transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import semantic_kernel as sk\n",
    "from semantic_kernel.connectors.ai import ChatRequestSettings, CompleteRequestSettings\n",
    "from semantic_kernel.connectors.ai.open_ai import AzureTextCompletion, AzureChatCompletion, OpenAITextCompletion, OpenAIChatCompletion\n",
    "from semantic_kernel.connectors.ai.hugging_face import HuggingFaceTextCompletion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "oai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "oai_org_id = os.getenv(\"OPENAI_ORG_ID\")\n",
    "deployment = os.getenv(\"AZURE_OPENAI_DEPLOYMENT_NAME\")\n",
    "api_key = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = sk.Kernel()\n",
    "\n",
    "# Configure Azure LLM service\n",
    "# deployment, api_key, endpoint = sk.azure_openai_settings_from_dot_env()\n",
    "azure_text_service = AzureTextCompletion(deployment, endpoint, api_key)\n",
    "azure_chat_service = AzureChatCompletion(deployment, endpoint, api_key)\n",
    "\n",
    "# Configure OpenAI service\n",
    "# api_key, org_id = sk.openai_settings_from_dot_env()\n",
    "oai_text_service = OpenAITextCompletion(\"text-davinci-003\", oai_api_key, oai_org_id)\n",
    "oai_chat_service = OpenAIChatCompletion(\"gpt-3.5-turbo\", oai_api_key, oai_org_id)\n",
    "\n",
    "# Configure Hugging Face service\n",
    "hf_text_service = HuggingFaceTextCompletion(\"distilgpt2\", task=\"text-generation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "request_settings = CompleteRequestSettings(\n",
    "    max_tokens=80,\n",
    "    temperature=0.7,\n",
    "    top_p=1,\n",
    "    frequency_penalty=0.5,\n",
    "    presence_penalty=0.5,\n",
    "    number_of_responses=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiple Open AI Text Completions\n",
    "prompt = \"what is the purpose of a rubber duck?\"\n",
    "results = await oai_text_service.complete_async(prompt, request_settings)\n",
    "i = 1\n",
    "for result in results:\n",
    "    print(f\"Result {i}: {result}\")\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiple Azure Open AI Text Completions\n",
    "prompt = \"provide me a list of possible meanings for the acronym 'ORLD'\"\n",
    "results = await azure_text_service.complete_async(prompt, request_settings)\n",
    "i = 1\n",
    "for result in results:\n",
    "    print(f\"Result {i}: {result}\")\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiple Hugging Face Text Completions\n",
    "prompt = \"The purpose of a rubber duck is\"\n",
    "results = await hf_text_service.complete_async(prompt, request_settings)\n",
    "i = 1\n",
    "for result in results:\n",
    "    print(f\"Result {i}: {result}\")\n",
    "    i += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "azureai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

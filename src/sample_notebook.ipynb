{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello World!\n"
     ]
    }
   ],
   "source": [
    "print(\"Hello World!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "app.py\n"
     ]
    }
   ],
   "source": [
    "fpath=\"c:\\\\Repository\\\\azure\\\\azureai\\\\src\\\\app.py\"\n",
    "print(fpath.split(\"\\\\\")[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------------------\n",
    "# Copyright (c) Microsoft Corporation. All rights reserved.\n",
    "# Licensed under the MIT License. See License.txt in the project root for\n",
    "# license information.\n",
    "# --------------------------------------------------------------------------\n",
    "\n",
    "\"\"\"\n",
    "FILE: sample_abstract_summary_async.py\n",
    "\n",
    "DESCRIPTION:\n",
    "    This sample demonstrates how to submit text documents for abstractive text summarization.\n",
    "    Abstractive summarization is available as an action type through the begin_analyze_actions API.\n",
    "\n",
    "    Abstractive summarization generates a summary that may not use the same words as those in\n",
    "    the document, but captures the main idea.\n",
    "\n",
    "USAGE:\n",
    "    python sample_abstract_summary_async.py\n",
    "\n",
    "    Set the environment variables with your own values before running the sample:\n",
    "    1) AZURE_LANGUAGE_ENDPOINT - the endpoint to your Language resource.\n",
    "    2) AZURE_LANGUAGE_KEY - your Language subscription key\n",
    "\"\"\"\n",
    "\n",
    "import asyncio\n",
    "\n",
    "\n",
    "async def sample_abstractive_summarization_async() -> None:\n",
    "    # [START abstract_summary_async]\n",
    "    import os\n",
    "    from azure.core.credentials import AzureKeyCredential\n",
    "    from azure.ai.textanalytics.aio import TextAnalyticsClient\n",
    "\n",
    "    endpoint = os.environ[\"AZURE_LANGUAGE_ENDPOINT\"]\n",
    "    key = os.environ[\"AZURE_LANGUAGE_KEY\"]\n",
    "\n",
    "    text_analytics_client = TextAnalyticsClient(\n",
    "        endpoint=endpoint,\n",
    "        credential=AzureKeyCredential(key),\n",
    "    )\n",
    "\n",
    "    document = [\n",
    "        \"At Microsoft, we have been on a quest to advance AI beyond existing techniques, by taking a more holistic, \"\n",
    "        \"human-centric approach to learning and understanding. As Chief Technology Officer of Azure AI Cognitive \"\n",
    "        \"Services, I have been working with a team of amazing scientists and engineers to turn this quest into a \"\n",
    "        \"reality. In my role, I enjoy a unique perspective in viewing the relationship among three attributes of \"\n",
    "        \"human cognition: monolingual text (X), audio or visual sensory signals, (Y) and multilingual (Z). At the \"\n",
    "        \"intersection of all three, there's magic-what we call XYZ-code as illustrated in Figure 1-a joint \"\n",
    "        \"representation to create more powerful AI that can speak, hear, see, and understand humans better. \"\n",
    "        \"We believe XYZ-code will enable us to fulfill our long-term vision: cross-domain transfer learning, \"\n",
    "        \"spanning modalities and languages. The goal is to have pretrained models that can jointly learn \"\n",
    "        \"representations to support a broad range of downstream AI tasks, much in the way humans do today. \"\n",
    "        \"Over the past five years, we have achieved human performance on benchmarks in conversational speech \"\n",
    "        \"recognition, machine translation, conversational question answering, machine reading comprehension, \"\n",
    "        \"and image captioning. These five breakthroughs provided us with strong signals toward our more ambitious \"\n",
    "        \"aspiration to produce a leap in AI capabilities, achieving multisensory and multilingual learning that \"\n",
    "        \"is closer in line with how humans learn and understand. I believe the joint XYZ-code is a foundational \"\n",
    "        \"component of this aspiration, if grounded with external knowledge sources in the downstream AI tasks.\"\n",
    "    ]\n",
    "    async with text_analytics_client:\n",
    "        poller = await text_analytics_client.begin_abstract_summary(document)\n",
    "        abstract_summary_results = await poller.result()\n",
    "        async for result in abstract_summary_results:\n",
    "            if result.kind == \"AbstractiveSummarization\":\n",
    "                print(\"Summaries abstracted:\")\n",
    "                [print(f\"{summary.text}\\n\") for summary in result.summaries]\n",
    "            elif result.is_error is True:\n",
    "                print(\"...Is an error with code '{}' and message '{}'\".format(\n",
    "                    result.error.code, result.error.message\n",
    "                ))\n",
    "    # [END abstract_summary_async]\n",
    "\n",
    "\n",
    "async def main():\n",
    "    await sample_abstractive_summarization_async()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    asyncio.run(main())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "azure",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
